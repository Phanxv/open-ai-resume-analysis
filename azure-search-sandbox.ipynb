{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.formrecognizer import DocumentAnalysisClient\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents.indexes.models import ComplexField, SearchableField, SimpleField, SearchIndex, SemanticConfiguration, SemanticField, SemanticPrioritizedFields, SemanticSearch\n",
    "import base64\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "import requests\n",
    "import json\n",
    "import string\n",
    "import random\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "AZURE_SEARCH_SERVICE_NAME = os.environ.get('AZURE_SEARCH_SERVICE_NAME')\n",
    "AZURE_SEARCH_API_KEY = os.environ.get('AZURE_SEARCH_API_KEY')\n",
    "INDEX_NAME = 'resume-index-test'\n",
    "AZURE_OPENAI_PREVIEW_API_VERSION=os.environ.get(\"AZURE_OPENAI_PREVIEW_API_VERSION\")\n",
    "AZURE_OPENAI_API_KEY=os.environ.get(\"AZURE_OPENAI_API_KEY\")\n",
    "AZURE_OPENAI_ENDPOINT=os.environ.get(\"AZURE_OPENAI_ENDPOINT\")\n",
    "AZURE_OPENAI_MODEL=os.environ.get(\"AZURE_OPENAI_MODEL\")\n",
    "AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT=os.environ.get(\"AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT\")\n",
    "AZURE_DOCUMENT_INTELLIGENCE_KEY=os.environ.get(\"AZURE_DOCUMENT_INTELLIGENCE_KEY\")\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_version= AZURE_OPENAI_PREVIEW_API_VERSION,\n",
    "    api_key=AZURE_OPENAI_API_KEY,\n",
    "    azure_endpoint=AZURE_OPENAI_ENDPOINT\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Document indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_search_index(semantic_config):\n",
    "    index_client = SearchIndexClient(\n",
    "        endpoint=f\"https://{AZURE_SEARCH_SERVICE_NAME}.search.windows.net\",\n",
    "        credential=AzureKeyCredential(AZURE_SEARCH_API_KEY)\n",
    "    )\n",
    "\n",
    "    fields = [\n",
    "        SimpleField(name=\"id\", type=\"Edm.String\", key=True),\n",
    "        SimpleField(name=\"name\", type=\"Edm.String\"),\n",
    "        SearchableField(name=\"content\", type=\"Edm.String\", analyzer_name=\"th.lucene\"),\n",
    "        SearchableField(name=\"summary\", type=\"Edm.String\", analyzer_name=\"th.lucene\"),\n",
    "        SimpleField(name=\"file_name\", type=\"Edm.String\")\n",
    "    ]\n",
    "    semantic_search = SemanticSearch(configurations=[semantic_config])\n",
    "    index = SearchIndex(name=INDEX_NAME, fields=fields, semantic_search=semantic_search)\n",
    "    index_client.create_index(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_config = SemanticConfiguration(\n",
    "    name=\"my-semantic-config\",\n",
    "    prioritized_fields=SemanticPrioritizedFields(\n",
    "        content_fields=[SemanticField(field_name=\"content\")],\n",
    "        keywords_fields=[SemanticField(field_name=\"summary\")]\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_search_index(semantic_config=semantic_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_openai_completion_request(full_text_extract):  \n",
    "    system_prompt = \"\"\"You are HR department assistant you job is to help summarize the data from job applicant\n",
    "            the data you need to extract is the keyword of Job title and Skill only answer with the keyword\n",
    "            in the form of plain text do not include any markdown\n",
    "            \"\"\"\n",
    "            \n",
    "    headers = {  \n",
    "        \"Content-Type\": \"application/json\",  \n",
    "        \"api-key\": AZURE_OPENAI_API_KEY,  \n",
    "    }  \n",
    "    \n",
    "    # Construct payload\n",
    "    payload = {  \n",
    "        \"messages\": [  \n",
    "            {  \n",
    "                \"role\": \"system\",  \n",
    "                \"content\": [  \n",
    "                    {  \n",
    "                        \"type\": \"text\",  \n",
    "                        \"text\": f\"{system_prompt}\" \n",
    "                    }  \n",
    "                ]  \n",
    "            },  \n",
    "            {  \n",
    "                \"role\": \"user\",  \n",
    "                \"content\": full_text_extract \n",
    "            },  \n",
    "        ],  \n",
    "        \"temperature\": 0.7,  \n",
    "        \"top_p\": 0.95,  \n",
    "        \"max_tokens\": 1500  \n",
    "    }   \n",
    "    \n",
    "    try:  \n",
    "        response = requests.post(AZURE_OPENAI_ENDPOINT+'/openai/deployments/gpt-4o-vision/chat/completions?api-version=2024-02-15-preview', headers=headers, json=payload, timeout=120)  \n",
    "        response.raise_for_status()  \n",
    "    except requests.RequestException as e:  \n",
    "        raise SystemExit(f\"Failed to make the request. Error: {e}\")  \n",
    "    except requests.exceptions.Timeout as e:\n",
    "        raise SystemExit(f\"Request timeout: {e}\")  \n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "PDF_HEADERS = {\n",
    "    \"title\": \"h1\",\n",
    "    \"sectionHeading\": \"h2\"\n",
    "}\n",
    "\n",
    "endpoint = AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT\n",
    "credential = AzureKeyCredential(AZURE_DOCUMENT_INTELLIGENCE_KEY)\n",
    "form_recognizer_client = DocumentAnalysisClient(endpoint, credential)\n",
    "def table_to_html(table):\n",
    "    table_html = \"<table>\"\n",
    "    rows = [sorted([cell for cell in table.cells if cell.row_index == i], key=lambda cell: cell.column_index) for i in range(table.row_count)]\n",
    "    for row_cells in rows:\n",
    "        table_html += \"<tr>\"\n",
    "        for cell in row_cells:\n",
    "            tag = \"th\" if (cell.kind == \"columnHeader\" or cell.kind == \"rowHeader\") else \"td\"\n",
    "            cell_spans = \"\"\n",
    "            if cell.column_span > 1: cell_spans += f\" colSpan={cell.column_span}\"\n",
    "            if cell.row_span > 1: cell_spans += f\" rowSpan={cell.row_span}\"\n",
    "            table_html += f\"<{tag}{cell_spans}>{html.escape(cell.content)}</{tag}>\"\n",
    "        table_html +=\"</tr>\"\n",
    "    table_html += \"</table>\"\n",
    "    return table_html\n",
    "\n",
    "def extract_pdf_content(file_path, form_recognizer_client, use_layout=False): \n",
    "    offset = 0\n",
    "    page_map = []\n",
    "    model = \"prebuilt-layout\" if use_layout else \"prebuilt-read\"\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        poller = form_recognizer_client.begin_analyze_document(model, document = f)\n",
    "    form_recognizer_results = poller.result()\n",
    "    # (if using layout) mark all the positions of headers\n",
    "    roles_start = {}\n",
    "    roles_end = {}\n",
    "    for paragraph in form_recognizer_results.paragraphs:\n",
    "        if paragraph.role!=None:\n",
    "            para_start = paragraph.spans[0].offset\n",
    "            para_end = paragraph.spans[0].offset + paragraph.spans[0].length\n",
    "            roles_start[para_start] = paragraph.role\n",
    "            roles_end[para_end] = paragraph.role\n",
    "\n",
    "    for page_num, page in enumerate(form_recognizer_results.pages):\n",
    "        tables_on_page = [table for table in form_recognizer_results.tables if table.bounding_regions[0].page_number == page_num + 1]\n",
    "\n",
    "        # (if using layout) mark all positions of the table spans in the page\n",
    "        page_offset = page.spans[0].offset\n",
    "        page_length = page.spans[0].length\n",
    "        table_chars = [-1]*page_length\n",
    "        for table_id, table in enumerate(tables_on_page):\n",
    "            for span in table.spans:\n",
    "                # replace all table spans with \"table_id\" in table_chars array\n",
    "                for i in range(span.length):\n",
    "                    idx = span.offset - page_offset + i\n",
    "                    if idx >=0 and idx < page_length:\n",
    "                        table_chars[idx] = table_id\n",
    "\n",
    "        # build page text by replacing charcters in table spans with table html and replace the characters corresponding to headers with html headers, if using layout\n",
    "        page_text = \"\"\n",
    "        added_tables = set()\n",
    "        for idx, table_id in enumerate(table_chars):\n",
    "            if table_id == -1:\n",
    "                position = page_offset + idx\n",
    "                if position in roles_start.keys():\n",
    "                    role = roles_start[position]\n",
    "                    if role in PDF_HEADERS:\n",
    "                        page_text += f\"<{PDF_HEADERS[role]}>\"\n",
    "                if position in roles_end.keys():\n",
    "                    role = roles_end[position]\n",
    "                    if role in PDF_HEADERS:\n",
    "                        page_text += f\"</{PDF_HEADERS[role]}>\"\n",
    "\n",
    "                page_text += form_recognizer_results.content[page_offset + idx]\n",
    "                \n",
    "            elif not table_id in added_tables:\n",
    "                page_text += table_to_html(tables_on_page[table_id])\n",
    "                added_tables.add(table_id)\n",
    "\n",
    "        page_text += \" \"\n",
    "        page_map.append((page_num, offset, page_text))\n",
    "        offset += len(page_text)\n",
    "\n",
    "    full_text = \"\".join([page_text for _, _, page_text in page_map])\n",
    "    return full_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_text = extract_pdf_content('./OneDrive_1_10-4-2024/pid_redacted/356LW841M3P0.pdf', form_recognizer_client, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = send_openai_completion_request(extracted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_text = response.json()['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_pdf(content, keyword):\n",
    "    # Initialize the search client\n",
    "    search_client = SearchClient(\n",
    "        endpoint=f\"https://{AZURE_SEARCH_SERVICE_NAME}.search.windows.net\",\n",
    "        index_name=INDEX_NAME,\n",
    "        credential=AzureKeyCredential(AZURE_SEARCH_API_KEY)\n",
    "    )\n",
    "    \n",
    "    # Create a document to index (adjust fields as per your index definition)\n",
    "    document = {\n",
    "        \"id\": \"356LW841M3P0\",\n",
    "        \"name\": \"Arthur Morgan\",\n",
    "        \"content\": str(content),\n",
    "        \"summary\": str(keyword),\n",
    "        \"file_name\": './OneDrive_1_10-4-2024/pid_redacted/356LW841M3P0.pdf'\n",
    "    }\n",
    "\n",
    "    # Upload the document to Azure Search\n",
    "    result = search_client.upload_documents(documents=[document])\n",
    "    print(f\"Uploaded document: {result}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_pdf(extracted_text, summary_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_client = SearchClient(\n",
    "        endpoint=f\"https://{AZURE_SEARCH_SERVICE_NAME}.search.windows.net\",\n",
    "        index_name=INDEX_NAME,\n",
    "        credential=AzureKeyCredential(AZURE_SEARCH_API_KEY)\n",
    "    )\n",
    "results = search_client.search(search_text='มีประสบการณ์ทำ ERP', select=[\"content\", \"summary\"],top=3)\n",
    "for result in results:  \n",
    "    print(f\"Score: {result['@search.score']}\")    \n",
    "    print(f\"Content: {result['content']}\\n\")\n",
    "    print(f\"Content: {result['summary']}\\n\")  \n",
    "    print(\"###############################\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -------------DEPRECATED-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = '''Extract these field from a resume \n",
    "\n",
    "Name (name) : Name of the applicant\n",
    "\n",
    "Contact Information (pid) : Name, phone number, email address, and sometimes a LinkedIn profile or portfolio link.\n",
    "\n",
    "Summary or Objective (intro) : A brief statement about career goals or a summary of qualifications.\n",
    "\n",
    "Work Experience (work) : Job titles, company names, dates of employment, employment duration (months or years calculate from date of employment), and key responsibilities or achievements.\n",
    "\n",
    "Education (education) : Degrees, schools, graduation dates, and sometimes relevant coursework or academic achievements.\n",
    "\n",
    "Skills (skills): A list of hard and soft skills relevant to the job.\n",
    "\n",
    "Competition (compatition) (optional) : Any competition that applicant have participated in\n",
    "\n",
    "Certifications (certifications) (optional) : Any certifications that are relevant to the job.\n",
    "\n",
    "Projects (projects) (Optional): Significant personal or professional projects, especially if relevant to the role.\n",
    "\n",
    "Awards & Honors (awards) (Optional): Any professional or academic awards.\n",
    "\n",
    "Languages (languages) (Optional): Any additional languages spoken or written.\n",
    "\n",
    "Reply with the json format with 3 keys \n",
    "1. name : the name of the applicant \n",
    "2. content : combine pid, summary, intro, work, education, skill, competition,certifications, project, award and language into a plain text data,\n",
    "3. summary : summerize work experience how long (months or years) does this applicant work in each job position and skillset that this applicant have in plain text English\n",
    "\n",
    "Do NOT include json markdown in the reply only json response'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def respone_extraction(response: requests.Response):\n",
    "    response_json = response.json()\n",
    "    response_json_dump = json.dumps(response_json, indent=2)\n",
    "    extracted_data = json.loads(response_json_dump)[\"choices\"][0][\"message\"][\"content\"]\n",
    "    return extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_extraction(filename: str, system_prompt: str) :\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"api-key\": AZURE_OPENAI_API_KEY,\n",
    "    }\n",
    "    payload = {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": f\"{system_prompt}\"\n",
    "                     }\n",
    "                ]\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\n",
    "                            \"url\": f\"data:image/jpeg;base64,{base64.b64encode(open(filename, 'rb').read()).decode('ascii')}\"\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        \"temperature\": 0.5,\n",
    "        \"top_p\": 0.95,\n",
    "        \"max_tokens\": 1500,\n",
    "        \"stream\": False\n",
    "    }\n",
    "\n",
    "    # Send request\n",
    "    try:\n",
    "        response = requests.post(AZURE_OPENAI_ENDPOINT+'/openai/deployments/gpt-4o-vision/chat/completions?api-version=2024-02-15-preview', headers=headers, json=payload)\n",
    "        response.raise_for_status()  # Will raise an HTTPError if the HTTP request returned an unsuccessful status code\n",
    "    except requests.RequestException as e:\n",
    "        raise SystemExit(f\"Failed to make the request. Error: {e}\")\n",
    "\n",
    "    # Handle the response as needed (e.g., print or process)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_pdf(file_path, system_prompt):\n",
    "    # Initialize the search client\n",
    "    search_client = SearchClient(\n",
    "        endpoint=f\"https://{AZURE_SEARCH_SERVICE_NAME}.search.windows.net\",\n",
    "        index_name=INDEX_NAME,\n",
    "        credential=AzureKeyCredential(AZURE_SEARCH_API_KEY)\n",
    "    )\n",
    "\n",
    "    # Extract the PDF file\n",
    "    extracted_response = respone_extraction(data_extraction(filename=file_path, system_prompt=system_prompt))\n",
    "    try :\n",
    "        extracted_data = json.loads(extracted_response)\n",
    "    except :\n",
    "        extracted_data = json.loads(extracted_response.replace(\"```json\\n\", \"\").replace(\"\\n```\", \"\"))\n",
    "    print(extracted_data)\n",
    "    # Create a document to index (adjust fields as per your index definition)\n",
    "    document = {\n",
    "        \"id\": ''.join(random.choices(string.ascii_uppercase + string.digits, k=12)),\n",
    "        \"name\": extracted_data['name'],\n",
    "        \"content\": extracted_data['content'],\n",
    "        \"summary\": extracted_data['summary'],\n",
    "        \"file_name\": os.path.basename(file_path)\n",
    "    }\n",
    "\n",
    "    # Upload the document to Azure Search\n",
    "    result = search_client.upload_documents(documents=[document])\n",
    "    print(f\"Uploaded document: {result}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_pdf(file_path=r'./uploads/phanxv/606faed39472eb276636b8f5_pdf-resume-template-format.jpg', system_prompt=system_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Document Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in results:  \n",
    "    print(f\"Score: {result['@search.score']}\")    \n",
    "    print(f\"Content: {result['content']}\\n\")   \n",
    "    print(\"###############################\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai-resume-analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
